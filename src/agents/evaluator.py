import pandas as pd

class EvaluatorAgent:
    """
    Validates hypotheses generated by the Insight Agent using real data.
    Assigns confidence scores and provides evidence.
    """

    def compute_confidence(self, value_diff, threshold):
        """
        Converts numeric deviation into a confidence score between 0 and 1.
        """
        raw = abs(value_diff) / threshold
        return min(1.0, round(raw, 2))


    def validate(self, hypotheses: list, df: pd.DataFrame):
        """
        Validates each hypothesis with numeric checks.
        """

        validated = []

        avg_ctr = df["ctr"].mean()
        avg_roas = df["roas"].mean()

        for h in hypotheses:

            category = h.get("category")

            # -------------------------------
            # Validate CTR hypotheses
            # -------------------------------
            if category == "ctr_issue":
                diff = avg_ctr - 0.02
                confidence = self.compute_confidence(diff, 0.02)

                validated.append({
                    "hypothesis": h["hypothesis"],
                    "evidence": h["evidence"],
                    "validated_truth": avg_ctr < 0.02,
                    "confidence": confidence
                })

            # -------------------------------
            # Validate ROAS hypotheses
            # -------------------------------
            elif category == "roas_issue":
                diff = 1.0 - avg_roas
                confidence = self.compute_confidence(diff, 1.0)

                validated.append({
                    "hypothesis": h["hypothesis"],
                    "evidence": h["evidence"],
                    "validated_truth": avg_roas < 1.0,
                    "confidence": confidence
                })

            # -------------------------------
            # Validate Creative Fatigue
            # -------------------------------
            elif category == "creative_fatigue":
                low_ctr_count = len(h["evidence"])
                confidence = min(1.0, low_ctr_count * 0.2)

                validated.append({
                    "hypothesis": h["hypothesis"],
                    "evidence": h["evidence"],
                    "validated_truth": low_ctr_count > 0,
                    "confidence": round(confidence, 2)
                })

            # -------------------------------
            # Validate Campaign Underperformance
            # -------------------------------
            elif category == "campaign_underperformance":
                camp = h["evidence"]
                diff = avg_roas - camp["roas"]
                confidence = self.compute_confidence(diff, avg_roas)

                validated.append({
                    "hypothesis": h["hypothesis"],
                    "evidence": h["evidence"],
                    "validated_truth": camp["roas"] < avg_roas * 0.8,
                    "confidence": confidence
                })

        return validated
